# Neural Network From Scratch

Hi! I am a computer science student and this repository is where I am keeping my neural network I am building from scratch! I am doing this project to gain a deeper (pun intended) understanding of neural networks.


## Setup

The only libraries you need to have are listed below with their pip installations. Numpy is used for linear algebra and tqdm is used to monitor training progress.

    pip install numpy
    pip install tqdm

## Features
### General
- [x] Multiple hidden layers
- [x] Backpropagation
- [x] Multiple activation functions
- [x] Learning rate scheduler
- [x] High level network builder
- [x] Save/Load model architecture and weights (customized file formats)
- [ ] Regularization
- [ ] Test/Train split


### Layers
- [x] Dense
- [ ] Dropout
- [ ] Memory
- [ ] Recurrent

### Optimizers
- [x] Gradient Descent
- [x] Momentum
- [ ] Stochastic Gradient Descent
- [ ] Nesterov Accelerated Gradient
- [ ] RMSProp
- [ ] Adam

## References

[A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)

[Learning Rate Schedules](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1)

[Overview of different Optimizers for neural networks](https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3)
